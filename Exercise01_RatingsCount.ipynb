{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Taming Big Data With Apache Spark and Python - Hands On!\n",
    "## Exercise 1.0 - Frequency of Movie Ratings\n",
    "\n",
    "### FindSpark\n",
    "This will circumvent many issues with your system finding spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('c:/users/andy/spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions\n",
    "* SparkConf: to run a Spark application on a local/cluster you need to set a few configurations and parameters\n",
    "    * setMaster: set master URL to connect to\n",
    "    * setAppName: create application name\n",
    "* SparkContext: main entry to Spark functionality, connection to a Spark cluster\n",
    "\n",
    "Set the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:/Users/Andy/Dropbox/FactoryFloor/Repositories/Tutorial_Udemy_SparkPython/Course_Resources/ml-100k/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure your Spark context; master node is local machine\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"RatingsHistogram\")\n",
    "\n",
    "# create a spark context object\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of Movie Ratings\n",
    "File was previously downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6110\n",
      "2 11370\n",
      "3 27145\n",
      "4 34174\n",
      "5 21201\n"
     ]
    }
   ],
   "source": [
    "# path to file of interest\n",
    "file_to_open = data_folder + \"u.data\"\n",
    "\n",
    "# load the file; textFile breaks up a data file so that each row represents a single value in an RDD\n",
    "lines = sc.textFile(file_to_open)\n",
    "\n",
    "# transform the RDD\n",
    "# split the string (i.e., each row) and take the third element (i.e., ratings)\n",
    "ratings = lines.map(lambda x: x.split()[2])\n",
    "\n",
    "# call an action on RDD\n",
    "# counts the number of times each unique value occurs\n",
    "result = ratings.countByValue()\n",
    "\n",
    "# use collection package to create an ordered dictionary\n",
    "sortedResults = collections.OrderedDict(sorted(result.items()))\n",
    "\n",
    "# print out each key and value in the ordered dictionary\n",
    "for key, value in sortedResults.items():\n",
    "    print(\"%s %i\" % (key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
